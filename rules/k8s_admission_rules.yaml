#
# Copyright (C) 2023 Richard Tweed.
# Copyright (C) 2022 The Falco Authors.
#
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

- required_engine_version: 15

- required_plugin_versions:
  - name: k8sadmission
    version: 0.0.0
  - name: json
    version: 0.6.0

# TODO, fix this as it's faulty
# Like always_true/always_false, but works with k8s audit events
- macro: k8s_admission_always_true
  condition: (evt.num != -1)

- macro: k8s_admission_never_true
  condition: (kar.uid="123")

# # Generally only consider audit events once the response has completed
# - list: k8s_admission_stages
#   items: ["ResponseComplete"]

# Generally exclude users starting with "system:"
- macro: non_system_user
  condition: (not kar.user.name startswith "system:")

# # This macro selects the set of Audit Events used by the below rules.
# - macro: kevt
#   condition: (jevt.value[/stage] in (k8s_admission_stages))

# - macro: kevt_started
#   condition: (jevt.value[/stage]=ResponseStarted)


# If you wish to restrict activity to a specific set of users, override/append to this list.
# users created by kops are included
- list: vertical_pod_autoscaler_users
  items: ["vpa-recommender", "vpa-updater"]

- list: allowed_k8s_users
  items: [
    "minikube", "minikube-user", "kubelet", "kops", "admin", "kube", "kube-proxy", "kube-apiserver-healthcheck",
    "kubernetes-admin",
    vertical_pod_autoscaler_users,
    cluster-autoscaler,
    "system:addon-manager",
    "cloud-controller-manager",
    "system:kube-controller-manager"
    ]

- list: eks_allowed_k8s_users
  items: [
    "eks:node-manager",
    "eks:certificate-controller",
    "eks:fargate-scheduler",
    "eks:k8s-metrics",
    "eks:authenticator",
    "eks:cluster-event-watcher",
    "eks:nodewatcher",
    "eks:pod-identity-mutating-webhook",
    "eks:cloud-controller-manager",
    "eks:vpc-resource-controller",
    "eks:addon-manager",
    ]
-
- rule: Disallowed K8s User
  desc: Detect any k8s operation by users outside of an allowed set of users.
  condition: non_system_user and not kar.user.name in (allowed_k8s_users) and not kar.user.name in (eks_allowed_k8s_users)
  output: K8s Operation performed by user not in allowed list of users (uid=%kar.uid user=%kar.user.name target=%kar.target.name/%kar.target.resource verb=%kar.verb  )
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

# In a local/user rules file, you could override this macro to
# explicitly enumerate the container images that you want to run in
# your environment. In this main falco rules file, there isn't any way
# to know all the containers that can run, so any container is
# allowed, by using the always_true macro. In the overridden macro, the condition
# would look something like (kar.req.pod.containers.image.repository in (my-repo/my-image))
- macro: allowed_k8s_containers
  condition: kar.req.pod.containers.image in (pause:123)

  # condition: (k8s_admission_always_true)

# - macro: response_successful
#   condition: (kar.response.code startswith 2)

- macro: kget
  condition: kar.verb=GET

- macro: kcreate
  condition: kar.verb=CREATE

- macro: kconnect
  condition: kar.verb=CONNECT

- macro: kmodify
  condition: (kar.verb in (CREATE,UPDATE,PATCH,ATTACH,CONNECT))

- macro: kdelete
  condition: kar.verb=DELETE

- macro: pod
  condition: kar.target.resource=pods and not kar.target.subresource exists

- macro: pod_subresource
  condition: kar.target.resource=pods and kar.target.subresource exists

- macro: deployment
  condition: kar.target.resource=deployments

- macro: service
  condition: kar.target.resource=services

- macro: configmap
  condition: kar.target.resource=configmaps

- macro: namespace
  condition: kar.target.resource=namespaces

- macro: serviceaccount
  condition: kar.target.resource=serviceaccounts

- macro: clusterrole
  condition: kar.target.resource=clusterroles

- macro: clusterrolebinding
  condition: kar.target.resource=clusterrolebindings

- macro: role
  condition: kar.target.resource=roles

- macro: secret
  condition: kar.target.resource=secrets

# - macro: health_endpoint
#   condition: kar.uri=/healthz

# - macro: live_endpoint
#   condition: kar.uri=/livez

# - macro: ready_endpoint
#   condition: kar.uri=/readyz

- rule: Create Disallowed Pod
  desc: >
    Detect an attempt to start a pod with a container image outside of a list of allowed images.
  condition: pod and kcreate and not allowed_k8s_containers
  output: Pod started with container not in allowed list (user=%kar.user.name pod=%kar.target.name ns=%kar.target.namespace images=%kar.req.pod.containers.image)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

- rule: Create Privileged Pod
  desc: >
    Detect an attempt to start a pod with a privileged container
  condition: pod and kcreate and kar.req.pod.containers.privileged intersects (true) and not kar.req.pod.containers.image.repository in (falco_privileged_images)
  output: Pod started with privileged container (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace images=%kar.req.pod.containers.image)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

- macro: sensitive_vol_mount
  condition: >
    (kar.req.pod.volumes.hostpath intersects (/proc, /var/run/docker.sock, /, /etc, /root, /var/run/crio/crio.sock, /run/containerd/containerd.sock, /home/admin, /var/lib/kubelet, /var/lib/kubelet/pki, /etc/kubernetes, /etc/kubernetes/manifests))

# - rule: Create Sensitive Mount Pod
#   desc: >
#     Detect an attempt to start a pod with a volume from a sensitive host directory (i.e. /proc).
#     Exceptions are made for known trusted images.
#   condition: pod and kcreate and sensitive_vol_mount and not kar.req.pod.containers.image.repository in (falco_sensitive_mount_images)
#   output: Pod started with sensitive mount (user=%kar.user.name pod=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resource images=%kar.req.pod.containers.image volumes=%jevt.value[/request/object/spec/volumes])
#   priority: WARNING
#   source: k8s_admission
#   tags: [k8s]

# These container images are allowed to run with hostnetwork=true
- list: falco_hostnetwork_images
  items: [
    gcr.io/google-containers/prometheus-to-sd,
    gcr.io/projectcalico-org/typha,
    gcr.io/projectcalico-org/node,
    gke.gcr.io/gke-metadata-server,
    gke.gcr.io/kube-proxy,
    gke.gcr.io/netd-amd64,
    k8s.gcr.io/ip-masq-agent-amd64,
    k8s.gcr.io/prometheus-to-sd,
    ]

# Corresponds to K8s CIS Benchmark 1.7.4
- rule: Create HostNetwork Pod
  desc: Detect an attempt to start a pod using the host network.
  condition: pod and kcreate and kar.req.pod.host_network intersects (true) and not kar.req.pod.containers.image.repository in (falco_hostnetwork_images)
  output: Pod started using host network (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace images=%kar.req.pod.containers.image)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

- list: falco_hostpid_images
  items: []

- rule: Create HostPid Pod
  desc: Detect an attempt to start a pod using the host pid namespace.
  condition: pod and kcreate and kar.req.pod.host_pid intersects (true) and not kar.req.pod.containers.image.repository in (falco_hostpid_images)
  output: Pod started using host pid namespace (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace images=%kar.req.pod.containers.image)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

- list: falco_hostipc_images
  items: []

- rule: Create HostIPC Pod
  desc: Detect an attempt to start a pod using the host ipc namespace.
  condition: pod and kcreate and kar.req.pod.host_ipc intersects (true) and not kar.req.pod.containers.image.repository in (falco_hostipc_images)
  output: Pod started using host ipc namespace (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace images=%kar.req.pod.containers.image)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

- macro: user_known_node_port_service
  condition: (k8s_admission_never_true)

- rule: Create NodePort Service
  desc: >
    Detect an attempt to start a service with a NodePort service type
  condition: service and kcreate and kar.req.service.type=NodePort and not user_known_node_port_service
  output: NodePort Service Created (user=%kar.user.name service=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace ports=%kar.req.service.ports)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

# TODO, equivalent for binaryData
- macro: contains_private_credentials
  condition: >
    (kar.req.configmap.data contains "aws_access_key_id" or
     kar.req.configmap.data contains "aws-access-key-id" or
     kar.req.configmap.data contains "aws_s3_access_key_id" or
     kar.req.configmap.data contains "aws-s3-access-key-id" or
     kar.req.configmap.data contains "password" or
     kar.req.configmap.data contains "passphrase")

- rule: Create/Modify Configmap With Private Credentials
  desc: >
     Detect creating/modifying a configmap containing a private credential (aws key, password, etc.)
  condition: configmap and kmodify and contains_private_credentials
  output: K8s configmap with private credential (user=%kar.user.name verb=%kar.verb resource=%kar.target.resource configmap=%kar.req.configmap.name config=%kar.req.configmap.data)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

# # Corresponds to K8s CIS Benchmark, 1.1.1.
# - rule: Anonymous Request Allowed
#   desc: >
#     Detect any request made by the anonymous user that was allowed
#   condition: kar.user.name=system:anonymous and kar.auth.decision="allow" and not health_endpoint and not live_endpoint and not ready_endpoint
#   output: Request by anonymous user allowed (user=%kar.user.name verb=%kar.verb  reason=%kar.auth.reason))
#   priority: WARNING
#   source: k8s_admission
#   tags: [k8s]

# Roughly corresponds to K8s CIS Benchmark, 1.1.12. In this case,
# notifies an attempt to exec/attach to a privileged container.

# Ideally, we'd add a more stringent rule that detects attaches/execs
# to a privileged pod, but that requires the engine for k8s audit
# events to be stateful, so it could know if a container named in an
# attach request was created privileged or not. For now, we have a
# less severe rule that detects attaches/execs to any pod.
#
# For the same reason, you can't use things like image names/prefixes,
# as the event that creates the pod (which has the images) is a
# separate event than the actual exec/attach to the pod.

- macro: user_known_exec_pod_activities
  condition: (k8s_admission_never_true)

- rule: Exec Pod
  desc: >
    Detect any attempt to exec in a pod
  condition: kar.target.subresource == exec and not user_known_exec_pod_activities
  output: Exec to pod (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace action=%kar.target.subresource command=kar.req.exec.command)
  priority: NOTICE
  source: k8s_admission
  tags: [k8s]

- rule: Attach to Pod
  desc: >
    Detect any attempt to attach to a pod
  condition: kar.target.subresource == attach and not user_known_exec_pod_activities
  output: Attach to pod (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace action=%kar.target.subresource)
  priority: NOTICE
  source: k8s_admission
  tags: [k8s]


- macro: user_known_exec_portforward_activities
  condition: (k8s_admission_never_true)

- rule: Portforward
  desc: >
    Detect any attempt to portforward to a pod
  condition: kar.target.subresource in (portforward) and not user_known_exec_portforward_activities
  output: Portforward to pod (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace)
  priority: NOTICE
  source: k8s_admission
  tags: [k8s]  

- macro: user_known_pod_debug_activities
  condition: (k8s_admission_never_true)

# TOOD: have someone with EphemeralContainers enabled test if this works
# # Only works when feature gate EphemeralContainers is enabled
# - rule: EphemeralContainers Created
#   desc: >
#     Detect any ephemeral container created
#   condition: pod_subresource and kmodify and kar.target.subresource in (ephemeralcontainers) and not user_known_pod_debug_activities
#   output: Ephemeral container is created in pod (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace ephemeral_container_name=%jevt.value[/request/object/ephemeralContainers/0/name] ephemeral_container_image=%jevt.value[/request/object/ephemeralContainers/0/image])
#   priority: NOTICE
#   source: k8s_admission
#   tags: [k8s]

# In a local/user rules fie, you can append to this list to add additional allowed namespaces
- list: allowed_namespaces
  items: [kube-system, kube-public, default]

- rule: Create Disallowed Namespace
  desc: Detect any attempt to create a namespace outside of a set of known namespaces
  condition: namespace and kcreate and not kar.target.name in (allowed_namespaces)
  output: Disallowed namespace created (user=%kar.user.name ns=%kar.target.name resource=%kar.target.resource)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

# Only defined for backwards compatibility. Use the more specific
# user_allowed_kube_namespace_image_list instead.
- list: user_trusted_image_list
  items: []

- list: user_allowed_kube_namespace_image_list
  items: [user_trusted_image_list]

# Only defined for backwards compatibility. Use the more specific
# allowed_kube_namespace_image_list instead.
- list: k8s_image_list
  items: []

- list: allowed_kube_namespace_image_list
  items: [
    gcr.io/google-containers/prometheus-to-sd,
    gcr.io/projectcalico-org/node,
    gke.gcr.io/addon-resizer,
    gke.gcr.io/heapster,
    gke.gcr.io/gke-metadata-server,
    k8s.gcr.io/ip-masq-agent-amd64,
    k8s.gcr.io/kube-apiserver,
    gke.gcr.io/kube-proxy,
    gke.gcr.io/netd-amd64,
    gke.gcr.io/watcher-daemonset,
    k8s.gcr.io/addon-resizer
    k8s.gcr.io/prometheus-to-sd,
    k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64,
    k8s.gcr.io/k8s-dns-kube-dns-amd64,
    k8s.gcr.io/k8s-dns-sidecar-amd64,
    k8s.gcr.io/metrics-server-amd64,
    kope/kube-apiserver-healthcheck,
    k8s_image_list
    ]

- macro: allowed_kube_namespace_pods
  condition: (kar.req.pod.containers.image.repository in (user_allowed_kube_namespace_image_list) or
              kar.req.pod.containers.image.repository in (allowed_kube_namespace_image_list))

# Detect any new pod created in the kube-system namespace
- rule: Pod Created in Kube Namespace
  desc: Detect any attempt to create a pod in the kube-system or kube-public namespaces
  condition: pod and kcreate and kar.target.namespace in (kube-system, kube-public) and not allowed_kube_namespace_pods
  output: Pod created in kube namespace (user=%kar.user.name pod=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace images=%kar.req.pod.containers.image)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

- list: user_known_sa_list
  items: []

- list: known_sa_list
  items: [
    coredns,
    coredns-autoscaler,
    cronjob-controller,
    daemon-set-controller,
    deployment-controller,
    disruption-controller,
    endpoint-controller,
    endpointslice-controller,
    endpointslicemirroring-controller,
    generic-garbage-collector,
    horizontal-pod-autoscaler,
    job-controller,
    namespace-controller,
    node-controller,
    persistent-volume-binder,
    pod-garbage-collector,
    pv-protection-controller,
    pvc-protection-controller,
    replicaset-controller,
    resourcequota-controller,
    root-ca-cert-publisher,
    service-account-controller,
    statefulset-controller
    ]

- macro: trusted_sa
  condition: (kar.target.name in (known_sa_list, user_known_sa_list))

# Detect creating a service account in the kube-system/kube-public namespace
- rule: Service Account Created in Kube Namespace
  desc: Detect any attempt to create a serviceaccount in the kube-system or kube-public namespaces
  condition: serviceaccount and kcreate and kar.target.namespace in (kube-system, kube-public)  and not trusted_sa
  output: Service account created in kube namespace (user=%kar.user.name serviceaccount=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

# Detect any modify/delete to any ClusterRole starting with
# "system:". "system:coredns" is excluded as changes are expected in
# normal operation.
- rule: System ClusterRole Modified/Deleted
  desc: Detect any attempt to modify/delete a ClusterRole/Role starting with system
  condition: (role or clusterrole) and (kmodify or kdelete) and (kar.target.name startswith "system:") and
             not kar.target.name in (system:coredns, system:managed-certificate-controller)
  output: System ClusterRole/Role modified or deleted (user=%kar.user.name role=%kar.target.name resource=%kar.target.resource ns=%kar.target.namespace action=%kar.verb)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

# Detect any attempt to create a ClusterRoleBinding to the cluster-admin user
# (expand this to any built-in cluster role that does "sensitive" things)
- rule: Attach to cluster-admin Role
  desc: Detect any attempt to create a ClusterRoleBinding to the cluster-admin user
  condition: clusterrolebinding and kcreate and kar.req.binding.role=cluster-admin
  output: Cluster Role Binding to cluster-admin role (user=%kar.user.name subject=%kar.req.binding.subjects)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

- rule: ClusterRole With Wildcard Created
  desc: Detect any attempt to create a Role/ClusterRole with wildcard resources or verbs
  condition: (role or clusterrole) and kcreate and (kar.req.role.rules.resources intersects ("*") or kar.req.role.rules.verbs intersects ("*"))
  output: Created Role/ClusterRole with wildcard (user=%kar.user.name role=%kar.target.name resource=%kar.target.resource rules=%kar.req.role.rules)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

- macro: writable_verbs
  condition: >
    (kar.req.role.rules.verbs intersects (create, update, patch, delete, deletecollection))

- rule: ClusterRole With Write Privileges Created
  desc: Detect any attempt to create a Role/ClusterRole that can perform write-related actions
  condition: (role or clusterrole) and kcreate and writable_verbs
  output: Created Role/ClusterRole with write privileges (user=%kar.user.name role=%kar.target.name resource=%kar.target.resource rules=%kar.req.role.rules)
  priority: NOTICE
  source: k8s_admission
  tags: [k8s]

- rule: ClusterRole With Pod Exec Created
  desc: Detect any attempt to create a Role/ClusterRole that can exec to pods
  condition: (role or clusterrole) and kcreate and kar.req.role.rules.resources intersects ("pods/exec")
  output: Created Role/ClusterRole with pod exec privileges (user=%kar.user.name role=%kar.target.name resource=%kar.target.resource rules=%kar.req.role.rules)
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

# The rules below this point are less discriminatory and generally
# represent a stream of activity for a cluster. If you wish to disable
# these events, modify the following macro.
- macro: consider_activity_events
  condition: (k8s_admission_always_true)

- macro: kactivity
  condition: (consider_activity_events)

- rule: K8s Deployment Created
  desc: Detect any attempt to create a deployment
  condition: (kactivity and kcreate and deployment )
  output: K8s Deployment Created (user=%kar.user.name deployment=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Deployment Deleted
  desc: Detect any attempt to delete a deployment
  condition: (kactivity and kdelete and deployment )
  output: K8s Deployment Deleted (user=%kar.user.name deployment=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Service Created
  desc: Detect any attempt to create a service
  condition: (kactivity and kcreate and service )
  output: K8s Service Created (user=%kar.user.name service=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Service Deleted
  desc: Detect any attempt to delete a service
  condition: (kactivity and kdelete and service )
  output: K8s Service Deleted (user=%kar.user.name service=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

# TODO, uncomment
# - rule: K8s ConfigMap Created
#   desc: Detect any attempt to create a configmap
#   condition: (kactivity and kcreate and configmap )
#   output: K8s ConfigMap Created (user=%kar.user.name configmap=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
#   priority: INFO
#   source: k8s_admission
#   tags: [k8s]

# - rule: K8s ConfigMap Deleted
#   desc: Detect any attempt to delete a configmap
#   condition: (kactivity and kdelete and configmap )
#   output: K8s ConfigMap Deleted (user=%kar.user.name configmap=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
#   priority: INFO
#   source: k8s_admission
#   tags: [k8s]

- rule: K8s Namespace Created
  desc: Detect any attempt to create a namespace
  condition: (kactivity and kcreate and namespace )
  output: K8s Namespace Created (user=%kar.user.name namespace=%kar.target.name resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Namespace Deleted
  desc: Detect any attempt to delete a namespace
  condition: (kactivity and non_system_user and kdelete and namespace )
  output: K8s Namespace Deleted (user=%kar.user.name namespace=%kar.target.name resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Serviceaccount Created
  desc: Detect any attempt to create a service account
  condition: (kactivity and kcreate and serviceaccount )
  output: K8s Serviceaccount Created (user=%kar.user.name serviceaccount=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Serviceaccount Deleted
  desc: Detect any attempt to delete a service account
  condition: (kactivity and kdelete and serviceaccount )
  output: K8s Serviceaccount Deleted (user=%kar.user.name serviceaccount=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Role/Clusterrole Created
  desc: Detect any attempt to create a cluster role/role
  condition: (kactivity and kcreate and (clusterrole or role) )
  output: K8s Cluster Role Created (user=%kar.user.name role=%kar.target.name resource=%kar.target.resource rules=%kar.req.role.ruleskar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Role/Clusterrole Deleted
  desc: Detect any attempt to delete a cluster role/role
  condition: (kactivity and kdelete and (clusterrole or role) )
  output: K8s Cluster Role Deleted (user=%kar.user.name role=%kar.target.name resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Role/Clusterrolebinding Created
  desc: Detect any attempt to create a clusterrolebinding
  condition: (kactivity and kcreate and clusterrolebinding )
  output: K8s Cluster Role Binding Created (user=%kar.user.name binding=%kar.target.name resource=%kar.target.resource subjects=%kar.req.binding.subjects role=%kar.req.binding.rolekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Role/Clusterrolebinding Deleted
  desc: Detect any attempt to delete a clusterrolebinding
  condition: (kactivity and kdelete and clusterrolebinding )
  output: K8s Cluster Role Binding Deleted (user=%kar.user.name binding=%kar.target.name resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Secret Created
  desc: Detect any attempt to create a secret. Service account tokens are excluded.
  condition: (kactivity and kcreate and secret and kar.target.namespace!=kube-system and non_system_user )
  output: K8s Secret Created (user=%kar.user.name secret=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

- rule: K8s Secret Deleted
  desc: Detect any attempt to delete a secret. Service account tokens are excluded.
  condition: (kactivity and kdelete and secret and kar.target.namespace!=kube-system and non_system_user )
  output: K8s Secret Deleted (user=%kar.user.name secret=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
  priority: INFO
  source: k8s_admission
  tags: [k8s]

# - rule: K8s Secret Get Successfully
#   desc: >
#     Detect any attempt to get a secret. Service account tokens are excluded.
#   condition: >
#     secret and kget
#     and kactivity
    
#   output: K8s Secret Get Successfully (user=%kar.user.name secret=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
#   priority: ERROR
#   source: k8s_admission
#   tags: [k8s]

# - rule:  K8s Secret Get Unsuccessfully Tried
#   desc: >
#     Detect an unsuccessful attempt to get the secret. Service account tokens are excluded.
#   condition: >
#     secret and kget
#     and kactivity
#     and not response_successful
#   output: K8s Secret Get Unsuccessfully Tried (user=%kar.user.name secret=%kar.target.name ns=%kar.target.namespace resource=%kar.target.resourcekar.req.configmap.data)
#   priority: WARNING
#   source: k8s_admission
#   tags: [k8s]

# This rule generally matches all events, and as a result is disabled
# by default. If you wish to enable these events, modify the
# following macro.
#  condition: (jevt.rawtime exists)
- macro: consider_all_events
  condition: (k8s_admission_never_true)

# - macro: kall
#   condition: (consider_all_events)

# TODO fix later
# - rule: All K8s Audit Events
#   desc: Match all K8s Audit Events
#   condition: consider_all_events
#   output: K8s Audit Event received (user=%kar.user.name verb=%kar.verb  obj=%jevt.obj)
#   priority: DEBUG
#   source: k8s_admission
#   tags: [k8s]


# This macro disables following rule, change to k8s_admission_never_true to enable it
- macro: allowed_full_admin_users
  condition: (k8s_admission_always_true)

# This list includes some of the default user names for an administrator in several K8s installations
- list: full_admin_k8s_users
  items: ["admin", "kubernetes-admin",  "kubernetes-admin@kubernetes", "kubernetes-admin@cluster.local", "minikube-user"]

# This rules detect an operation triggered by an user name that is
# included in the list of those that are default administrators upon
# cluster creation. This may signify a permission setting too broader.
# As we can't check for role of the user on a general kar.* event, this
# may or may not be an administrator. Customize the full_admin_k8s_users
# list to your needs, and activate at your discretion.

# # How to test:
# # Execute any kubectl command connected using default cluster user, as:
# kubectl create namespace rule-test

- rule: Full K8s Administrative Access
  desc: Detect any k8s operation by a user name that may be an administrator with full access.
  condition: >
    non_system_user
    and kar.user.name in (full_admin_k8s_users)
    and not allowed_full_admin_users
  output: K8s Operation performed by full admin user (user=%kar.user.name target=%kar.target.name/%kar.target.resource verb=%kar.verb  )
  priority: WARNING
  source: k8s_admission
  tags: [k8s]

# - rule: Trigger on all events
#   desc: Trigger on all events for debugging
#   condition: kar.uid != "abc"
#   output: Got an event (uid=%kar.uid)
#   priority: DEBUG
#   source: k8s_admission
#   tags: [k8s]

- macro: ingress
  condition: kar.target.resource=ingresses

- macro: ingress_tls
  condition: (jevt.value[/request/object/spec/tls] exists)

# # How to test:
# # Create an ingress.yaml file with content:
# apiVersion: networking.k8s.io/v1beta1
# kind: Ingress
# metadata:
#   name: test-ingress
#   annotations:
#     nginx.ingress.kubernetes.io/rewrite-target: /
# spec:
#   rules:
#   - http:
#       paths:
#       - path: /testpath
#         backend:
#           serviceName: test
#           servicePort: 80
# # Execute: kubectl apply -f ingress.yaml

# TODO fix later
# - rule: Ingress Object without TLS Certificate Created
#   desc: Detect any attempt to create an ingress without TLS certification.
#   condition: >
#     (kcreate and ingress and not ingress_tls)
#   output: >
#     K8s Ingress Without TLS Cert Created (user=%kar.user.name ingress=%kar.target.name
#     namespace=%kar.target.namespace resource=%kar.target.resource)
#   source: k8s_admission
#   priority: WARNING
#   tags: [k8s, network]

- macro: node
  condition: kar.target.resource=nodes

- macro: allow_all_k8s_nodes
  condition: (k8s_admission_always_true)

- list: allowed_k8s_nodes
  items: []

# # How to test:
# # Create a Falco monitored cluster with Kops
# # Increase the number of minimum nodes with:
# kops edit ig nodes
# kops apply --yes

- rule: Untrusted Node Successfully Joined the Cluster
  desc: >
    Detect a node successfully joined the cluster outside of the list of allowed nodes.
  condition: >
    node
    and kcreate
    and not allow_all_k8s_nodes
    and not kar.target.name in (allowed_k8s_nodes)
  output: Node not in allowed list successfully joined the cluster (user=%kar.user.name node=%kar.target.name resource=%kar.target.resource)
  priority: ERROR
  source: k8s_admission
  tags: [k8s]
